{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcholic Anonymous News articles extraction from The Daily Star. Data Extraction of following parameters\n",
    "- Headline\n",
    "- Description\n",
    "- Author\n",
    "- Published Date\n",
    "- Category\n",
    "- Publication\n",
    "- News\n",
    "- URL\n",
    "- Keywords\n",
    "- Summary\n",
    "\n",
    "### Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options # enables options in web browser\n",
    "from selenium import webdriver # web-based automation tool for Python\n",
    "from newspaper import Article # Article scraping & curation\n",
    "from bs4 import BeautifulSoup # Python library for pulling data out of HTML and XML files\n",
    "from requests import get # standard for making HTTP requests in Python\n",
    "import pandas as pd # library written for data manipulation and analysis\n",
    "import sys, time #  System-specific parameters and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Empty lists for Alcholic Anonymous News Articles parameters data to be extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines, descriptions, dates, authors, news, keywords, summaries, urls, category, publication = [], [], [], [], [], [], [], [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the total no.of.pages by total no.of articles from google search resultsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'Alcoholics Anonymous site:www.thedailystar.net'\n",
    "\n",
    "url = 'https://www.google.com/search?q=' + '+'.join(keyword.split())\n",
    "\n",
    "soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "try:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 680 results (0.23 seconds)\n",
    "    max_pages = round([int(s) for s in soup.select_one('div#resultStats').text.split() if s.isdigit()][0]/10)\n",
    "    max_pages = max_pages + 1\n",
    "except:\n",
    "    # Extracts the digits if it the resulted number without comma ','. eg: About 1,080 results (0.23 seconds)\n",
    "    max_pages = round(int(''.join(i for i in soup.select_one('div#resultStats').text if i.isdigit()))/10)\n",
    "    max_pages = max_pages + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates max_pages value through while loop. Scraping the Articles urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome(options=options)\n",
    "browser.get(url)\n",
    "\n",
    "index = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        index +=1\n",
    "        page = browser.page_source\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        linky = [soup.select('.r')[i].a['href'] for i in range(len(soup.select('.r')))]\n",
    "        urls.extend(linky)\n",
    "        if index == max_pages:\n",
    "            break\n",
    "        browser.find_element_by_xpath('//*[@id=\"pnnext\"]/span[2]').click()\n",
    "        time.sleep(2)\n",
    "        sys.stdout.write('\\r' + str(index) + ' : ' + str(max_pages) + '\\r')\n",
    "        sys.stdout.flush()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To remove duplicates urls entries in the list by executing below line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Extracted URL's are : 8 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "urls = list(dict.fromkeys(urls))\n",
    "print(\"Total Extracted URL's are\" + ' : ' + str(len(urls)), type(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterates urls through for loop. Scraping the Articles with above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.3 shedailystar.net/news/and-god-created-the-french-by-louis-bernard-robitaille0Report_Dawn%20%281%29.pdf\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for index, url in enumerate(urls):\n",
    "    try:\n",
    "        # Parse the url to NewsPlease \n",
    "        soup = BeautifulSoup(get(url).text, 'lxml')\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        \n",
    "        # Extracts the Headlines\n",
    "        try:\n",
    "            try:\n",
    "                headlines.append(soup.select_one('meta[property=\"og:title\"]')['content'].strip())\n",
    "            except:\n",
    "                headlines.append(article.title.strip())\n",
    "        except:\n",
    "            headlines.append(None)\n",
    "            \n",
    "        # Extracts the Descriptions    \n",
    "        try:\n",
    "            try:\n",
    "                descriptions.append(soup.select_one('meta[property=\"og:description\"]')['content'].strip().replace('\\n', ' '))\n",
    "            except:\n",
    "                descriptions.append(article.meta_description.strip())\n",
    "        except:\n",
    "            descriptions.append(None)\n",
    "            \n",
    "        # Extracts the Authors\n",
    "        try:\n",
    "            try:\n",
    "                authors.append(soup.select_one('.detailed-content').select_one('span[itemprop=\"name\"]').a.text.strip())\n",
    "            except:\n",
    "                authors.append(article.authors.strip())\n",
    "        except:\n",
    "            authors.append(None)\n",
    "        \n",
    "        # Extracts the published dates\n",
    "        try:\n",
    "            try:\n",
    "                dates.append(soup.select_one('meta[property=\"article:published_time\"]')['content'].strip())\n",
    "            except:\n",
    "                dates.append(str(article.publish_date))\n",
    "        except:\n",
    "            dates.append(None)\n",
    "            \n",
    "        # Extracts the news articles\n",
    "        try:\n",
    "            try:\n",
    "                news.append(soup.select_one('.storyText').text.replace('\\n', '').strip())\n",
    "            except:\n",
    "                news.append(' '.join(article.text.split()).replace(\"\\'\\'\",\" \").replace(\"\\'\", \"\").replace(\" / \", \"\"))\n",
    "        except:\n",
    "            news.append(None)\n",
    "            \n",
    "        # Extracts the news category\n",
    "        try:\n",
    "            category.append(article.meta_data['category'])\n",
    "        except:\n",
    "            category.append(None)\n",
    "            \n",
    "        # Extracts the news publication\n",
    "        try:\n",
    "            publication.append(article.meta_data['og']['site_name'])\n",
    "        except:\n",
    "            publication.append(None)\n",
    "\n",
    "        # Extracts Keywords and Summaries\n",
    "        try:\n",
    "            keywords.append(article.keywords)\n",
    "            summaries.append(article.summary)\n",
    "        except:\n",
    "            keywords.append(None)\n",
    "            summaries.append(None)\n",
    "                        \n",
    "    except:\n",
    "        headlines.append(None)\n",
    "        descriptions.append(None)\n",
    "        authors.append(None)\n",
    "        dates.append(None)\n",
    "        category.append(None)\n",
    "        publication.append(None)\n",
    "        news.append(None)\n",
    "        keywords.append(None)\n",
    "        summaries.append(None)\n",
    "\n",
    "    sys.stdout.write('\\r' + str(index) + ' : ' + str(url) + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Array Length of each list to create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8 8 8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "print(len(headlines), len(descriptions), len(authors), len(dates), len(category), len(publication), len(news), len(keywords), len(summaries), len(urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a csv file after checking array length and droping the missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published_Dates</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Articles</th>\n",
       "      <th>category</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Summaries</th>\n",
       "      <th>Source_URLs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Serenity in the South China Sea</td>\n",
       "      <td>The central, painful reality that the US must ...</td>\n",
       "      <td>Gareth Evans</td>\n",
       "      <td>2015-07-03T00:00:00+06:00</td>\n",
       "      <td>The Daily Star</td>\n",
       "      <td>Diplomats and alcoholics dont always have as m...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[islands, serenity, china, claims, zone, sea, ...</td>\n",
       "      <td>The dramatic build-up of China's military (esp...</td>\n",
       "      <td>https://www.thedailystar.net/op-ed/politics/se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UN chief accuses India of intolerance with gay...</td>\n",
       "      <td>United Nations Chief Ban Ki-moon has accused I...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-01-14T00:00:46+06:00</td>\n",
       "      <td>The Daily Star</td>\n",
       "      <td>United Nations Chief Ban Ki-moon has accused I...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[tawadkar, intolerance, sex, chief, accuses, g...</td>\n",
       "      <td>United Nations Chief Ban Ki-moon has accused I...</td>\n",
       "      <td>https://www.thedailystar.net/un-chief-accuses-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India ruling party minister slammed over plans...</td>\n",
       "      <td>Indian Prime Minister Narendra Modi's ruling p...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-01-14T00:00:52+06:00</td>\n",
       "      <td>The Daily Star</td>\n",
       "      <td>Indian Prime Minister Narendra Modis ruling pa...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[long, slammed, tawadkar, goa, normal, modis, ...</td>\n",
       "      <td>Indian Prime Minister Narendra Modi's ruling p...</td>\n",
       "      <td>https://www.thedailystar.net/india-ruling-part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous people and the insidious logic of pe...</td>\n",
       "      <td>POLITICAL violence is as old as the memory of ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-10T00:00:00+06:00</td>\n",
       "      <td>The Daily Star</td>\n",
       "      <td>POLITICAL violence is as old as the memory of ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[streets, phenomenon, insidious, bomb, identit...</td>\n",
       "      <td>Such a generalisation, however justified, glos...</td>\n",
       "      <td>https://www.thedailystar.net/op-ed/anonymous-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How is he doing?</td>\n",
       "      <td>Set in a serene location, Sunrise Guest House ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-07-27T00:00:42+06:00</td>\n",
       "      <td>The Daily Star</td>\n",
       "      <td>Set in a serene location, Sunrise Guest House ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[rs, long, doing, rent, guest, shillong, days,...</td>\n",
       "      <td>Asked about how he was paying the rent, he ref...</td>\n",
       "      <td>https://www.thedailystar.net/frontpage/how-he-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Headlines  \\\n",
       "0                    Serenity in the South China Sea   \n",
       "1  UN chief accuses India of intolerance with gay...   \n",
       "2  India ruling party minister slammed over plans...   \n",
       "3  Anonymous people and the insidious logic of pe...   \n",
       "4                                   How is he doing?   \n",
       "\n",
       "                                        Descriptions       Authors  \\\n",
       "0  The central, painful reality that the US must ...  Gareth Evans   \n",
       "1  United Nations Chief Ban Ki-moon has accused I...          None   \n",
       "2  Indian Prime Minister Narendra Modi's ruling p...          None   \n",
       "3  POLITICAL violence is as old as the memory of ...          None   \n",
       "4  Set in a serene location, Sunrise Guest House ...          None   \n",
       "\n",
       "             Published_Dates     Publication  \\\n",
       "0  2015-07-03T00:00:00+06:00  The Daily Star   \n",
       "1  2015-01-14T00:00:46+06:00  The Daily Star   \n",
       "2  2015-01-14T00:00:52+06:00  The Daily Star   \n",
       "3  2015-02-10T00:00:00+06:00  The Daily Star   \n",
       "4  2015-07-27T00:00:42+06:00  The Daily Star   \n",
       "\n",
       "                                            Articles category  \\\n",
       "0  Diplomats and alcoholics dont always have as m...       {}   \n",
       "1  United Nations Chief Ban Ki-moon has accused I...       {}   \n",
       "2  Indian Prime Minister Narendra Modis ruling pa...       {}   \n",
       "3  POLITICAL violence is as old as the memory of ...       {}   \n",
       "4  Set in a serene location, Sunrise Guest House ...       {}   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  [islands, serenity, china, claims, zone, sea, ...   \n",
       "1  [tawadkar, intolerance, sex, chief, accuses, g...   \n",
       "2  [long, slammed, tawadkar, goa, normal, modis, ...   \n",
       "3  [streets, phenomenon, insidious, bomb, identit...   \n",
       "4  [rs, long, doing, rent, guest, shillong, days,...   \n",
       "\n",
       "                                           Summaries  \\\n",
       "0  The dramatic build-up of China's military (esp...   \n",
       "1  United Nations Chief Ban Ki-moon has accused I...   \n",
       "2  Indian Prime Minister Narendra Modi's ruling p...   \n",
       "3  Such a generalisation, however justified, glos...   \n",
       "4  Asked about how he was paying the rent, he ref...   \n",
       "\n",
       "                                         Source_URLs  \n",
       "0  https://www.thedailystar.net/op-ed/politics/se...  \n",
       "1  https://www.thedailystar.net/un-chief-accuses-...  \n",
       "2  https://www.thedailystar.net/india-ruling-part...  \n",
       "3  https://www.thedailystar.net/op-ed/anonymous-p...  \n",
       "4  https://www.thedailystar.net/frontpage/how-he-...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(headlines) == len(descriptions) == len(authors) == len(dates) == len(news) == len(publication) == len(keywords) == len(summaries) == len(urls) == len(category):\n",
    "    tbl = pd.DataFrame({'Headlines' : headlines,\n",
    "                        'Descriptions' : descriptions,\n",
    "                        'Authors' : authors,\n",
    "                        'Published_Dates' : dates,\n",
    "                        'Publication' : publication,\n",
    "                        'Articles' : news,\n",
    "                        'category' : category,\n",
    "                        'Keywords' : keywords,\n",
    "                        'Summaries' : summaries,\n",
    "                        'Source_URLs' : urls})\n",
    "    tbl.dropna()\n",
    "    path = 'C:\\\\Users\\\\GM\\\\Desktop\\\\!Code!\\\\CDRI\\\\Alcoholics Anonymous\\\\Data Extraction\\\\#Dataset\\\\'\n",
    "    tbl.to_csv(path+'The_Daily_Star.csv', index=False)\n",
    "else:\n",
    "    print('Array lenght does not match!')\n",
    "\n",
    "tbl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tbl.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
